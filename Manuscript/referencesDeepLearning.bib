%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Nicholas Tustison at 2018-05-10 16:25:07 -0700 


%% Saved with string encoding Unicode (UTF-8) 



@webpage{antsrnet,
	Date-Added = {2018-05-10 23:23:39 +0000},
	Date-Modified = {2018-05-10 23:25:07 +0000},
	Url = {https://github.com/ANTsX/ANTsRNet}}

@inproceedings{Nair2010,
	Author = {Vinod Nair and Geoffrey E. Hinton},
	Booktitle = {Proceedings of the 27th International Conference on Machine Learning},
	Date-Added = {2018-05-10 23:09:37 +0000},
	Date-Modified = {2018-05-10 23:10:19 +0000},
	Title = {Rectified Linear Units Improve Restricted Boltzmann Machines},
	Year = {2010}}

@article{Srivastava2014,
	Author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	Date-Added = {2018-05-10 23:03:02 +0000},
	Date-Modified = {2018-05-10 23:04:32 +0000},
	Journal = {Journal of Machine Learning Research},
	Month = {Jan},
	Number = {1},
	Pages = {1929--1958},
	Title = {Dropout: A Simple Way to Prevent Neural Networks from Overfittin},
	Volume = {15},
	Year = {2014}}

@article{Fukushima:1980aa,
	Abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by "learning without a teacher", and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname "neocognitron". After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consists of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of "S-cells", which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of "C-cells" similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any "teacher" during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cells of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
	Author = {Fukushima, K},
	Date-Added = {2018-05-10 22:32:33 +0000},
	Date-Modified = {2018-05-10 22:32:33 +0000},
	Journal = {Biol Cybern},
	Journal-Full = {Biological cybernetics},
	Mesh = {Cognition; Computers; Form Perception; Learning; Models, Neurological; Nerve Net; Nervous System Physiological Phenomena; Pattern Recognition, Visual},
	Number = {4},
	Pages = {193-202},
	Pmid = {7370364},
	Pst = {ppublish},
	Title = {Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
	Volume = {36},
	Year = {1980}}

@article{HUBEL:1962aa,
	Author = {HUBEL, D H and WIESEL, T N},
	Date-Added = {2018-05-10 22:31:26 +0000},
	Date-Modified = {2018-05-10 22:31:26 +0000},
	Journal = {J Physiol},
	Journal-Full = {The Journal of physiology},
	Keywords = {CEREBRAL CORTEX/physiology},
	Mesh = {Animals; Cats; Cerebral Cortex; Visual Cortex},
	Month = {Jan},
	Pages = {106-54},
	Pmc = {PMC1359523},
	Pmid = {14449617},
	Pst = {ppublish},
	Title = {Receptive fields, binocular interaction and functional architecture in the cat's visual cortex},
	Volume = {160},
	Year = {1962}}

@article{LeCun1998,
	Author = {Y. LeCun and L. Bottou and Y. Bengio and P. Haffner},
	Date-Added = {2018-05-10 21:51:33 +0000},
	Date-Modified = {2018-05-10 22:20:35 +0000},
	Journal = {Proceedings of the IEEE},
	Month = {Nov},
	Number = {11},
	Pages = {2278 - 2324},
	Title = {Gradient-based learning applied to document recognition},
	Volume = {86},
	Year = {1998}}

@article{Shelhamer:2017aa,
	Abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional networks achieve improved segmentation of PASCAL VOC (30% relative improvement to 67.2% mean IU on 2012), NYUDv2, SIFT Flow, and PASCAL-Context, while inference takes one tenth of a second for a typical image.},
	Author = {Shelhamer, Evan and Long, Jonathan and Darrell, Trevor},
	Date-Added = {2018-05-10 21:34:24 +0000},
	Date-Modified = {2018-05-10 21:34:24 +0000},
	Doi = {10.1109/TPAMI.2016.2572683},
	Journal = {IEEE Trans Pattern Anal Mach Intell},
	Journal-Full = {IEEE transactions on pattern analysis and machine intelligence},
	Month = {Apr},
	Number = {4},
	Pages = {640-651},
	Pmid = {27244717},
	Pst = {ppublish},
	Title = {Fully Convolutional Networks for Semantic Segmentation},
	Volume = {39},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1109/TPAMI.2016.2572683}}

@webpage{ssd7,
	Date-Added = {2018-04-27 02:09:34 +0000},
	Date-Modified = {2018-04-27 02:10:32 +0000},
	Lastchecked = {April 26, 2018},
	Url = {https://github.com/pierluigiferrari/ssd_keras},
	Bdsk-Url-1 = {https://github.com/pierluigiferrari/ssd_keras}}

@inproceedings{Ronneberger:2015aa,
	Author = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
	Booktitle = {Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention},
	Date-Added = {2018-04-23 02:02:20 +0000},
	Date-Modified = {2018-04-23 02:04:39 +0000},
	Pages = {234-241},
	Publisher = {Springer},
	Series = {LNCS},
	Title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	Volume = {9351},
	Year = {2015}}

@article{Russakovsky:2015aa,
	Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
	Date-Added = {2018-04-22 23:12:38 +0000},
	Date-Modified = {2018-05-03 18:44:19 +0000},
	Journal = {International Journal of Computer Vision},
	Month = {December},
	Number = {3},
	Pages = {211-252},
	Title = {{ImageNet} Large Scale Visual Recognition Challenge},
	Volume = {115},
	Year = {2015}}

@article{LeCun:2015aa,
	Author = {Yann LeCun and Yoshua Bengio and Geoffrey Hinton},
	Date-Added = {2018-04-22 22:56:12 +0000},
	Date-Modified = {2018-04-22 22:58:09 +0000},
	Journal = {Nature},
	Month = {May},
	Pages = {436-444},
	Title = {Deep learning},
	Volume = {521},
	Year = {2015}}

@article{AlexNet,
	Acmid = {3065386},
	Address = {New York, NY, USA},
	Author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	Doi = {10.1145/3065386},
	Issn = {0001-0782},
	Issue_Date = {June 2017},
	Journal = {Commun. ACM},
	Month = may,
	Number = {6},
	Numpages = {7},
	Pages = {84--90},
	Publisher = {ACM},
	Title = {ImageNet Classification with Deep Convolutional Neural Networks},
	Url = {http://doi.acm.org/10.1145/3065386},
	Volume = {60},
	Year = {2017},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/3065386},
	Bdsk-Url-2 = {https://doi.org/10.1145/3065386}}

@article{VNet,
	Archiveprefix = {arXiv},
	Author = {Fausto Milletari and Nassir Navab and Seyed{-}Ahmad Ahmadi},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/MilletariNA16},
	Eprint = {1606.04797},
	Journal = {CoRR},
	Timestamp = {Wed, 07 Jun 2017 14:40:44 +0200},
	Title = {V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation},
	Url = {http://arxiv.org/abs/1606.04797},
	Volume = {abs/1606.04797},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1606.04797}}

@article{Taylor:2017aa,
	Archiveprefix = {arXiv},
	Author = {Luke Taylor and Geoff Nitschke},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/abs-1708-06020},
	Eprint = {1708.06020},
	Journal = {CoRR},
	Timestamp = {Tue, 05 Sep 2017 10:03:46 +0200},
	Title = {Improving Deep Learning using Generic Data Augmentation},
	Url = {http://arxiv.org/abs/1708.06020},
	Volume = {abs/1708.06020},
	Year = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1708.06020}}
