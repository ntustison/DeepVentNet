
# DISCUSSION

<!-- 

Potential of deep learning over JLF:  JLF only operates on a voxelwise
(not learned features like deep learning) so with deep learning we can
learn something like the trachea which will confuse JLF.  Perhaps show
a picture where JLF is in the trachea.

-->

Significant progress has been made from earlier quantification approaches
in which human labelers manually identified areas of poor ventilation or 
applied simple thresholding techniques.  More sophisticated automated and 
semi-automated techniques have advanced our ability to investigate the use
of hyperpolarized gas imaging as quantitative image-based biomarkers.
Deep learning techniques can further enhance these methodologies by 
potentially increasing accuracy, generalizability, and computational 
efficiency.  In this work, we provided a deep learning framework for 
segmentation of structural and functional lung MRI for quantification
of ventilation.  This framework is based on the U-net architecture and
implemented using the Keras API available through the R statistical project.


There are several limitations to the proposed framework. The most obvious
is that it only leverages the full 3-D nature of the image data collected
for the proton segmentation. 
The trained models for ventilation image segmentation were based on 2-D coronal 
slices and therefore subsequent
prediction is limited to those views.  Even though good results were achieved
in this study, even better results might be achieved by training 3-D
models for the latter.  Also, evaluative
comparison was made using manually-refined segmentations which is certainly
useful but additional evaluations using various clinical measures would
also be helpful in determining the relative utility of various segmentation approaches.
For example, how does the performance of the various methods translate
into utility as an imaging biomarker for lung function?

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{./Figures/0058ProtonProblemCases.pdf}
\caption{Problematic case showing potential issues with the JLF approach (left)
for proton lung segmentation where a difficult pairwise image registration 
caused segmentation failure.  In contrast, by learning features directly,
the U-net approach (right) avoids possible registration difficulties.
}
\label{fig:problemCaseProton}
\end{figure}

Despite these limitations of the proposed framework, there are also limitations 
of previously reported methods.  For example, in addition to the significant 
time requirements for JLF of lung images, shown in \ref{fig:problemCaseProton}
is an example where difficult pairwise image registration scenarios can cause 
algorithmic failures.  In contrast, the trained U-net model is capable of learning
features which can potentially circumvent registration failures.  Similarly, 
the online feature capabilities of deep learning can overcome some of the 
drawbacks to more conventional segmentation approaches of ventilation lung images.
A well-known artifact for these approaches are partial voluming effects which 
can confound unsophisticated intensity-based segmentation approaches.  Although 
spatial regularization
(e.g., Markov random fields) can reduce some of these effects, these are based
on relatively simplistic assumptions and it is possible that more complicated
modeling can reduce these effects (see Figure \ref{fig:problemCaseVentilation}).

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{./Figures/UVa_He3_140_slice8.pdf}
\caption{Ventilation segmentation comparison between a human reader
and the two computational approaches.  Notice the effects of the partial
voluming at the apex of the lungs which are labeled as ventilation 
defect by the Atropos approach whereas U-net and the human reader 
correctly label this region.
}
\label{fig:problemCaseVentilation}
\end{figure}


Future research will certainly look into these issues as potential improvements 
to the existing framework.  As a surrogate for full 3-D models, we are looking into 
developing additional 2-D U-net models for the axial and sagittal views. Since 
slice-by-slice processing is computationally efficient in the deep learning paradigm,
we can process 3-D images along the three canonical axes and combined the results 
for increased accuracy.  More broadly, it would be of potential interest to investigate
the use of image classification techniques (e.g., VGG [@Simonyan:2014]) for classifying 
lung disease phenotype directly from the images.  \textcolor{blue}{More immediate 
benefits could result from augmenting the limited, single-site data set used
in this work to include data contributed from other groups which could translate into
more robust models.  Additionally, as the U-net architecture is application-agnostic,
investigators can apply the contributions discussed in this work to their own data, 
such as lung CT, to facilitate their own research.}  
