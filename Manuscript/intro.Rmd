
# INTRODUCTION 

Probing lung function under a variety of conditions and/or pathologies
has been significantly facilitated by the use of hyperpolarized gas
imaging and corresponding quantitative image analysis methodologies. 
Such developments have provided direction and opportunity for current 
and future research trends [@Liu:2014aa].  Computational techniques 
targeting these imaging technologies permit 
quantification of spatial ventilation with potential for increased reproducibility,
resolution, and robustness over traditional spirometry and radiological
readings [@Roos:2015aa;@Adamson:2017aa]. 

In this research context, one of the most frequently used image-based biomarkers for 
the study of pulmonary development and disease is based on the quantification 
of regions of limited ventilation, also known as _ventilation defects_.
These features have been shown to be particularly salient in a clinical context, 
for example ventilation defect volume to total lung volume ratio has been shown 
to outperform other image-based features in discriminating asthmatics vs. 
non-asthmatics [@Tustison:2010aa].
This has motivated the development of multiple automated (and semi-automated) 
segmentation algorithms which have been proposed in the literature
[@Tustison:2011aa;@Kirby:2012aa;@He:2014aa;@Zha:2016aa;@Hughes:2018aa]
and are currently used in a variety of clinical research investigations 
(e.g., [@Trivedi:2017aa]).

Despite the enormous methodological progress, recent developments in maching 
learning (specifically "deep learning" 
[@LeCun:2015aa]) have generated new possibilities for quantification 
with improved capabilities in terms of accuracy, robustness, and 
computational efficiency.
Deep learning, a term connoting neural network architectures with 
multiple hidden layers, has gained prominence in recent years due, in large
part, to the annual ImageNet Large Scale Visual Recognition Challenge [@Russakovsky:2015aa].
Specifically, one of the participants of the 2012 ImageNet challenge, a convolutional 
neural network colloquially known as "AlexNet" [@AlexNet],
significantly surpassed anything that had been proposed previously.
The subsequent outgrowth of research, in conjunction with advances
in computational hardware, has resulted in significant developments 
in various image research areas including classification, segmentation,
and object localization and has led to co-optation by the medical imaging 
analysis community [@Litjens:2017aa].

In this work, we develop and evaluate a convolutional neural network 
segmentation framework, based on the U-net architecture [@Ronneberger:2015aa], 
for functional lung imaging using hyperpolarized gas.  As part of this framework
we include a deep learning counterpart to earlier work from our group targeting
segmentation of proton lung MRI [@Tustison:2016aa].  This is motivated by 
common use case scenarious in which proton images are used for quantifying 
corresponding ventilation images (e.g., [@Tustison:2011aa;@Kirby:2012aa;@He:2014aa]).

One of the drawbacks
to deep learning approaches are the large data requirements for
the training process oftentimes necessitating ad hoc strategies for 
simulating additional data from available data---a process termed _data augmentation_ [@Taylor:2017aa].
While common approaches to data augmentation  might include the application
of randomized simulated linear (e.g., translation, rotation and shearing) 
or elastic transformations and intensity adjustments (e.g., brightness and contrast), we propose
an approach tailored to medical imaging scenarios.
In the proposed approach, an optimal shape-based template is constructed 
from a subset of the available data.   Subsequent pairwise image registration 
between all training data and the resulting template permits a "pseudo-geodesic"
transformation of each image to every other image thus converting a data set of size
$N$ to an augmented data set of size $N^2$.  In this way, transformations are 
constrainted to the shape space representing the population of interest.

To enhance relevance to the research community, we showcase this work in 
conjunction with the introduction of _ANTsRNet_---a growing open-source 
repository of well-known deep learning architectures which interfaces with the 
Advanced Normalization Tools (ANTs) package [@antsr] and its interface with the R 
statistical project (i.e., ANTsR) [@antsr].  This permits the public distribution of
all code, data, and models which can be found on the GitHub repository corresponding
to this manuscript [@deepventnet]

