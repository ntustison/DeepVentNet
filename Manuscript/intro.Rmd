
# INTRODUCTION 

Probing lung function under a variety of conditions and/or pathologies
has been significantly facilitated by the use of hyperpolarized gas
imaging and corresponding quantitative image analysis methodologies. 
Such developments have provided direction and opportunity for current 
and future research trends [@Liu:2014aa].  Computational techniques 
targeting these imaging technologies permit spatial
quantification of localized ventilation with potential for increased reproducibility,
resolution, and robustness over traditional spirometry and radiological
readings [@Roos:2015aa;@Adamson:2017aa]. 

One of the most frequently used image-based biomarkers for 
the study of pulmonary development and disease is based on the quantification 
of regions of limited ventilation, also known as _ventilation defects_ [@Svenningsen:2014aa].
These features have been shown to be particularly salient in a clinical context.
For example, ventilation defect volume to total lung volume ratio has been shown 
to outperform other image-based features in discriminating asthmatics vs. 
non-asthmatics [@Tustison:2010aa].  Ventilation defects have also demonstrated 
discriminative capabilities in chronic obstructive pulmonary disease (COPD) [@Kirby:2014aa]
and asthma [@Altes:2016aa].
These findings, along with related research, \textcolor{black}{have} motivated the development of multiple automated (and semi-automated) 
segmentation algorithms which have been proposed in the literature (e.g., 
[@Tustison:2011aa;@Kirby:2012aa;@He:2014aa;@Zha:2016aa;@Hughes:2018aa])
and are currently used in a variety of clinical research investigations 
(e.g., [@Trivedi:2017aa]).

Despite the enormous methodological progress with existing quantification strategies, 
recent developments in machine learning (specifically "deep learning" 
[@LeCun:2015aa]) have generated new possibilities for quantification 
with improved capabilities in terms of accuracy, robustness, and 
computational efficiency.
Deep learning, a term denoting neural network architectures with 
multiple hidden layers, has seen recent renewed research development and application.  In the field of 
image analysis and computer vision, deep learning with convolution neural networks (CNNs)
has been particularly prominent in recent years due, in large part, to the annual ImageNet Large Scale Visual 
Recognition Challenge [@Russakovsky:2015aa].
Specifically, one of the participating groups in the 2012 ImageNet challenge was the earliest 
adopter of CNNs.  The resulting architecture, colloquially known as "AlexNet" [@AlexNet],
surpassed any approach that had been proposed previously and laid the groundwork for
future CNN-based architectures for image classification such as VGG [@Simonyan:2014] and
GoogLeNet [@Szegedy:2015].  The recent successes of CNNs are historically rooted in the 
pioneering work of LeCun et al. [@LeCun1998] and Fukushima [@Fukushima:1980aa] and others
which drew inspiration from earlier work on the complex arrangement of cells within 
the feline visual cortex [@HUBEL:1962aa].  CNNs are characterized by common components (i.e.,
convolution, pooling, and activation functions) which can be put together in various 
arrangements to perform such tasks as image classification and voxelwise segmentation.
The outgrowth of research, in conjunction with advances
in computational hardware, has resulted in significant developments 
in various image research areas including classification, segmentation,
and object localization and has led to co-optation by the medical imaging 
analysis community [@Litjens:2017aa].

In this work, we develop and evaluate a convolutional neural network 
segmentation framework, based on the U-net architecture [@Ronneberger:2015aa], 
for functional lung imaging using hyperpolarized gas.  As part of this framework
we include a deep learning analog to earlier work from our group targeting
segmentation of proton lung MRI [@Tustison:2016aa].  This is motivated by 
common use case scenarios in which \textcolor{black}{proton images are used to identify regions of 
interest in corresponding ventilation images} [@Tustison:2011aa;@Kirby:2012aa;@He:2014aa], 
\textcolor{black}{which typically contain no discernible boundaries for anatomic structures.}

One of the practical constraints 
to adopting deep learning techniques is the large data requirement for
the training process oftentimes necessitating ad hoc strategies for 
simulating additional data from available data---a process termed _data augmentation_ [@Taylor:2017aa].
While common approaches to data augmentation include the application
of randomized simulated linear (e.g., translation, rotation and affine) 
or elastic transformations and intensity adjustments (e.g., brightness and contrast), 
we advocate a tailored paradigm to commonly encountered medical imaging scenarios
in which data is limited but is assumed to be characterized by a population-wide 
spatial correspondence.  In the proposed approach, an optimal shape-based template is constructed 
from a subset of the available data.   Subsequent pairwise image registration 
between all training data and the resulting template permits a "pseudo-geodesic"
transformation [@Tustison:2013ac] of each image to every other image thus potentially 
converting a data set of size
$N$ to an augmented data set of size $N^2$.  In this way, transformations are 
constrained to the shape space representing the population of interest.

To enhance relevance to the research community, we showcase this work in 
conjunction with the introduction of _ANTsRNet_---a growing open-source 
repository of well-known deep learning architectures which interfaces with the 
Advanced Normalization Tools (ANTs) package [@Avants:2011ab] and its R package,
ANTsR [@antsr].  This permits the public distribution of
all code, data, and models for external reproducibility which can be found on 
the GitHub repository corresponding to this manuscript [@deepventnet].  This 
allows other researchers to apply the developed models and software to their 
data and/or use the models to initialize their own model development tailored 
to specific studies. 

In the work described below, we first provide the acquisition protocols for both
the proton and ventilation MR images followed by a discussion of the analysis 
methodologies for the proposed segmentation framework.  This is 
contextualized with a brief overview of existing quantification methods (including
that previously proposed by our group and used for the evaluative comparison).  We
also summarize the key contributions of this work viz., the template-based data 
augmentation and the current feature set of ANTsRNet.



