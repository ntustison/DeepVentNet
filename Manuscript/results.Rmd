
# RESULTS

## Proton MRI lung segmentation

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{./Figures/diceProton.pdf}
\caption{The Dice overlap coefficient for the left and right lungs (and their 
combination) between the updated joint label fusion technique (left)
and our deep learning approach (right).  Although slightly less accurate,
the latter requires significantly less computation time.
}
\label{fig:diceProton}
\end{figure}

After constructing the U-net structural model using template-based
data augmentation\footnote{
Although the need for data augmentation techniques is well-established within the
deep learning research community, we performed a smaller 2-D experiment to 
illustrate the potential gain using template-based data augmentation over 
\textcolor{blue}{augmentation and augmentation using randomly generated deformable transforms.}
Training
data consisted of 50 coronal proton lung MRI with 
lung segmentations.  Data and scripts are available in the companion repository to
the ANTsRNet package, called ANTsRNetExamples, which contains examples for
available architectures.  
Accuracy, in terms of Dice overlap, achieved with template-based augmentation was
left lung: 0.94 $\pm$ 0.02, 
right lung:  0.92 $\pm$ 0.04, and
whole lung: 0.93 $\pm$ 0.03.
Accuracy achieved without augmentation was
left lung: 0.88 $\pm$ 0.13, 
right lung:  0.83 $\pm$ 0.21, and
whole lung: 0.86 $\pm$ 0.16.
\textcolor{blue}{Accuracy achieved with random deformation augmentation was
left lung: 0.94 $\pm$ 0.03, 
right lung:  0.90 $\pm$ 0.06, and
whole lung: 0.92 $\pm$ 0.04.}
}, we applied it to the evaluation data consisting
of the same 62 proton MRI used in [@Tustison:2011aa].  We performed a direct 
comparison with the joint label fusion (JLF) method of [@Tustison:2011aa] with
an adopted modification that we currently use in our studies.  Instead of using
the entire atlas set (which would require a large number of pairwise image 
registrations), we align the center of the image to be segmented with 
each atlas image and compute a neighborhood cross-correlation similarity metric 
[@Avants:2011ab].  We then select the 10 atlas images that are most similar for
use in the JLF scheme. The resulting performance numbers (in terms of Dice overlap)
are similar to what we obtained previously and are given in Figure \ref{fig:diceProton} 
along with the Dice overlap numbers from the CNN-based approach.
\textcolor{black}{Accuracy for the latter was left lung: 0.93 $\pm$ 0.03, right lung:  0.94 $\pm$ 0.02, and
whole lung: 0.94 $\pm$ 0.02.}  The analagous JLF numbers were slightly more accurate 
(left lung: 0.95 $\pm$ 0.02, right lung: 0.96 $\pm$ 0.01, whole lung: 0.96 $\pm$ 0.01)
although the processing time is significantly 
greater---less than 1 second per subject for the proposed approach versus ~25 minutes per subject
using JLF using 4 CPU threads running 8 parallel pairwise registrations per 
evaluation image.


## Ventilation MRI lung segmentation

We applied the deep learning approach described in the previous section to 
the evaluation data used in [@Tustison:2011aa].   The resulting probability images were converted into a single segmentation
image which were then compared with the manual segmentation results and Atropos
results from our previous work [@Tustison:2011aa].  Note
that the Otsu thresholding and K-means thresholding were omitted as they were 
the poorest performers and, as mentioned previously, discard spatial information
in contrast to both computational methods and the human readers.  

In the absence of ground truth, the STAPLE algorithm [@Warfield:2004aa] was used 
to create a consensus labeling.  The Dice overlap coefficient was used to quantify
agreement between each of the segmentation raters and the consensus labeling as
an indicator performance.  The results are shown in Figure \ref{fig:diceVentilation}.
Mean values ($\pm$ standard deviation) were as follows (total, normal lung, ventilation
defect):
Reader 1: 0.89 $\pm$ 0.07, 0.91 $\pm$ 0.06, 0.6 $\pm$ 0.3;
Reader 2: 0.92 $\pm$ 0.05, 0.94 $\pm$ 0.04, 0.57 $\pm$ 0.3;
Reader 3: 0.94 $\pm$ 0.03, 0.96 $\pm$ 0.03, 0.63 $\pm$ 0.3; 
Atropos:  0.92 $\pm$ 0.03, 0.94 $\pm$ 0.03, 0.71 $\pm$ 0.3; and
U-net:    0.94 $\pm$ 0.03, 0.96 $\pm$ 0.03, 0.70 $\pm$ 0.3.
Computational time for processing was slightly less than a minute per subject for
Atropos, between 30--45 for the human readers, and less than a second for the 
U-net model.  


\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{./Figures/ventilationStaple.pdf}
\caption{The Dice overlap coefficient for total, normal lung, and 
ventilation defect regions for segmentation of the evaluation data
set.  
}
\label{fig:diceVentilation}
\end{figure}



<!--

Using both 3He and 1H image data, which were acquired simultaneously, a trained 
radiologist (denoted ‘‘Radiologist 3’’ in Table 1 and Fig. 9) segmented the whole 
lungs for each of 18 subjects (4 normals and 14 diagnosed subjects with cystic 
fibrosis) using the ITK-SNAP image annotation tool (23). By simultaneously referring 
to both coregistered images, in which the mouse cursor was linked between the two 
image sets, manual segmentation was facilitated over using either modality alone. 
This and two other radiologists, as well as the first author, manually segmented the 
ventilation defects within the masked lung regions for all 18 subjects. Atropos was 
also used to segment the ventilation defects using four classes where the lower two 
classes represented the ventilation defect regions and the upper two classes 
represented the normal ventilation regions.  Since there is no ground truth for these 
data, a consensus labeling using the simultaneous truth and performance level 
estimation (STAPLE) algorithm (24) was used as a probabilistic estimate of the 
ground truth segmentation for each of the 18 subjects. The identification of the 
defect and normally ventilated regions produced by each of the five readers (both 
human and Atropos) for each of the 18 subjects resulted in 18 * 5 1⁄4 90 total 
segmentations. Fusing several segmentations of the same object by different raters, 
STAPLE iteratively estimates the performance level of each rater while simultaneously 
producing a probabilistic estimate of the true segmentation. In this fashion, STAPLE 
was used to produce 18 such proba- bilistic ground truth estimates, one for each subject. 
Since a byproduct of STAPLE is a performance estima- tion of each rater, performance 
comparison for each rater for each subject can be analyzed. Tabulating the sensitivity 
and specificity values of each rater over all 18 subjects on a voxel-by-voxel basis 
summarizes this comparison. Although not included with the STAPLE consensus estimation, 
we calculated the K-means and Otsu voxel classifications (using four classes) for each 
subject and also used the STAPLE probabilistic esti- mate of the ground truth to 
calculate the sensitivity and specificity values for these methods.

-->