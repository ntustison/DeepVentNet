
# MATERIALS AND METHODS

## _Image acquisition_

<!--

Imaging with hyperpolarized 3He was performed under an Institutional Review Board 
(IRB)-approved protocol with written informed consent obtained from each subject. 
In addition, all imaging was performed under an Food and Drug Administration 
(FDA)-approved physician’s Investigational New Drug application (IND 57866) 
for hyperpolarized 3He. MRI data were acquired on a 1.5 T whole-body MRI scanner 
(Siemens Sonata, Siemens Medical Solutions, Malvern, PA) with broadband 
capabilities and a flexible 3He chest radiofrequency coil (RF; IGC Medical 
Advances, Milwaukee, WI; or Clinical MR Solutions, Brookfield, WI). During a 
10–20-second breath-hold following the inhalation of %300 mL of hyperpolarized 
3He mixed with %700 mL of nitrogen, a set of 19–28 contiguous axial sections 
were collected. Parameters of the fast low angle shot sequence for 3He MRI 
were as follows: repetition time msec / echo time msec, 7/3; flip angle
10$^\circ$; matrix, 80  128; field of view, 26  42 cm; section thickness, 10 mm; 
and intersection gap, none. The data were deidentified prior to analysis.

-->

MR imaging was performed using a 1.5T commercial scanner (Avanto, Siemens Medical 
Solutions, Malvern PA).   A 3-D gradient-echo based MR pulse sequence was used to 
acquire images covering the whole lung with isotropic resolution of 3.9 mm. 
Other parameters include  TR= 1.80 ms, TE= 0.78 ms, flip angle= 9 degree, 
bandwidth= 1090 Hz/Pixel. Total acquisition time varies between 5-8 seconds 
depending on the size of the subjects. 

## Preprocessing

\begin{figure}
\centering
\includegraphics[width=\textwidth]{./Figures/N4Denoised.pdf}
\caption{Sample image showing the effects of preprocessing on the proton MRI. (a) 
Uncorrected image showing MR field inhomogeneity and noise. (b) Corresponding corrected 
image in which the bias and noise effects have been ameliorated.}
\label{fig:n4denoised}
\end{figure}

## Template-based data augmentation

In addition to these software contributions, a significant methodological contribution 
we have made is the design of a template-based data augmentation strategy.  The need
for large training data sets is a well-known limitation associated with deep learning 
algorithms.  Whereas the architectures developed for such tasks as the ImageNet 
competition have access to millions of annotated images, such data access is not always
is available and such is typically the case in medical imaging.  In order to achieve
data set sizes necessary for learning functional models, various data augmentation 
strategies have been employed. These include application of intensity transformations, 
such as brightening and enhanced contrast, and simple spatial transformations, 
such as arbitrary rotations and translations.  Regarding the latter, such transformations
are not ideal as they might not reflect what is typically seen in medical images and
might not sufficiently sample the shape-space of the population currently being 
studied.  

We currently use a template-based approach whereby image data sampled from the population
is used to construct a representative template that is optimal in terms of both shape and 
intensity [@Avants:2010aa].  In addition to the representative template, this template-building 
process yields the transformations to/from each individual image to the template space.
This permits a propagation of the training data to the space of each individual image. In 
the simplest case, the training data is used to construct the template and then each 
individual training data is propagated to the space of every other individual training
data.  In this way, a training data set of size $N$ can be expanded to a data set of 
size $N^2$ (cf Figure 1).  A more complicated use case could build a template from $M$ data sets 
(where $M > N$).  Transformations between the training data and the template could then
be used to propagate the training data to the spaces of the individual members of the 
template-generating data for an augmented data set size of $M \times N$. 

\begin{figure}
\centering
\includegraphics[width=\textwidth]{./Figures/DataAugmentation.pdf}
\caption{We introduce a novel data augmentation strategy for medical images using 
ANTs-based template construction.  Shown here is the 2-D U-net example where 
we create a template from the training data segmentation images where the 
foreground designates the left and right lungs.  This avoids the lack of 
internal correspondence while generating plausible global shape variations 
when mapping between individual training data.  We used 60+ images to 
create such a template permitting 60$^2$ = 3600 possible deformable shapes 
which can be further augmented by more conventional strategies (e.g., brightness
transformations, translations, etc.).}
\label{fig:augmentation}
\end{figure}

## ANTsRNet

The recent interest in deep learning techniques and the associated successes with respect to a 
variety of applications has motivated adoption of such techniques within the medical imaging 
research community.  Basic image operations such as classification, object identification, and 
segmentation (as well as more focused techniques) has significant potential for facilitating 
basic medical research.  In light of these new developments, and in order to better meet the 
modern needs of the community, we have modified this specific aim for ITK-Lung to include 
the implementation and dissemination of open-source deep learning architectures relevant to 
the use cases of our partner investigators.  

Towards this end, we have created _ANTsRNet_--a collection of well-known deep learning 
architectures ported to the R language.  ANTsRNet is built using the Keras neural network 
library (available through R) and is highly integrated with the ANTsR package, the R interface 
of the ANTs toolkit.  Consistent with our other software offerings, ongoing development is 
currently carried out on GitHub using a well-commented coding style, thorough documentation, 
and self-contained working examples.  

It should be noted that various implementations of different deep learning 
architectures exist and are largely available to the public.  However, we feel 
that this work fills an unmet need.  Based on our own search, many publicly 
available implementations, while functional, are not developed with large-scale distribution 
and application as end goals.  There is little, if any, coding consistency between the 
various implementations leading to non-standardized APIs and difficulties in code
navigation for debugging and/or didactic reasons.  In addition, the vast majority employ the
Python language which is understandable given its widespread usage by data scientists.
However, this work makes these powerful new developments available through a major platform 
heavily used by statisticians and data scientists alike.
In addition, the R-based interface to the ANTs toolkit allows for preprocessing and data
augmentation strategies specific to medical imaging.  As a result of these current efforts,
we were recently awarded a Titan XP GPU from the NVIDIA corporation for facilitating ongoing 
development.

Although much work remains to be completed, we have made significant progress. As noted below,
several architectures have been implemented for both 2-D and 3-D images spanning the broad
application areas of image classification, object detection, and image segmentation. 
It should be noted that most reporting in the literature has dealt exclusively with 2-D 
implementations.  This is understandable due to memory and computational speed constraints
limiting practical 3-D application on current hardware.  However, given the importance that
3-D data has for medical imaging and the rapid progress in hardware, we  feel it worth
the investment in implementing corresponding 3-D architectures.  Each 
architecture is accompanied by one or more self-contained examples for testing and illustrative
purposes.  In addtion, we have made novel data augmentation strategies available to the user 
and illustrated them with Keras-specific batch generators.    These contributions are outlined 
below.  

\input{antsrnetTable.tex}

---
nocite: |
  @Ronneberger:2015, @Milletari:2016, @Krizhevsky:2012, @Simonyan:2014, @Szegedy:2015, @He:2015, @Xie:2016, @Huang:2016, @Liu:2015, @ssd7}
...
