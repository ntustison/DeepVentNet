

\begin{table}[!htb]
\centering
\caption{Current ANTsRNet capabilities comprising architectures for applications in 
image segmentation, image classification, and object localization.  Self-contained
examples with data are also provided to demonstrate usage for each of the architectures.}
\label{table:antsrnet}
\begin{tabular*}{\textwidth}{ll@{\extracolsep{\fill}}l}
\toprule
\multicolumn{3}{c}{\textbf{ANTsRNet}}    \\        
\midrule
\multicolumn{3}{l}{\textbf{Image Segmentation}}
  \vspace{0.25cm} \\ \vspace{0.2cm} 
  U-net \cite{Ronneberger:2015} & (2-D) & 
    \begin{minipage}[t]{0.6\columnwidth}%
        Extends fully convolutional neural networks by 
        including an upsampling decoding path with skip connections 
        linking corresponding encoding/decoding layers. %
    \end{minipage} \\ \vspace{0.3cm} 
  V-net \cite{Milletari:2016} & (3-D) &
    \begin{minipage}[t]{0.6\columnwidth}%
        3-D extension of U-net which incorporates a customized
        Dice loss function. %
    \end{minipage} \\
\midrule
\multicolumn{3}{l}{\textbf{Image Classification}} 
  \vspace{0.25cm} \\ \vspace{0.2cm} 
  AlexNet \cite{Krizhevsky:2012} & (2-D, 3-D) & 
    \begin{minipage}[t]{0.6\columnwidth}%
        Convolutional neural network that precipitated renewed
        interest in neural networks.
    \end{minipage} \\ \vspace{0.2cm} 
  VGG16/VGG19 \cite{Simonyan:2014} & (2-D, 3-D) & 
    \begin{minipage}[t]{0.6\columnwidth}%
        Also known as 'OxfordNet'.  VGG architectures are much 
        deeper than AlexNet.  Two popular styles are implemented. %
    \end{minipage} \\ \vspace{0.2cm} 
  GoogLeNet \cite{Szegedy:2015} & (2-D) & 
    \begin{minipage}[t]{0.6\columnwidth}%
        A 22-layer network formed from {\em inception blocks} meant
        to reduce the number of parameters.
    \end{minipage} \\ \vspace{0.2cm} 
  ResNet \cite{He:2015}  & (2-D, 3-D) & 
    \begin{minipage}[t]{0.6\columnwidth}%
        Characterized by specialized {\em residualized blocks} (and
        skip connections. %
    \end{minipage} \\ \vspace{0.2cm} 
  ResNeXt \cite{Xie:2016} & (2-D, 3-D) &
    \begin{minipage}[t]{0.6\columnwidth}%
        A variant of ResNet distinguished by a hyper-parameter called 
        {\em cardinality} definining the number of independent paths. %
    \end{minipage} \\ \vspace{0.3cm} 
  DenseNet \cite{Huang:2016} & (2-D, 3-D) & 
    \begin{minipage}[t]{0.6\columnwidth}%
        Based on the observation that performance is typically enhanced 
        with shorter connections between the layers and the input.%
    \end{minipage} \\
\midrule    
\multicolumn{3}{l}{\textbf{Object Localization}} 
  \vspace{0.25cm} \\ \vspace{0.2cm} 
  SSD300/SSD512 \cite{Liu:2015} & (2-D, 3-D) & 
    \begin{minipage}[t]{0.6\columnwidth}%
        The Multibox Single-Shot Detection (SSD) algorithm for
        determining bounding boxes around objects of interest. %
    \end{minipage} \\ \vspace{0.2cm} 
  SSD7 \cite{ssd7} & (2-D, 3-D) & 
    \begin{minipage}[t]{0.6\columnwidth}%
        Lightweight version which increases speed by sacrificing
        accuracy.  Training size requirements are smaller. %
  \end{minipage} \\
\bottomrule
\end{tabular*}
\end{table}


% \nocite{Ronneberger:2015,Milletari:2016,Krizhevsky:2012,Simonyan:2014,Szegedy:2015,He:2015,Xie:2016,Huang:2016,Liu:2015}

% __Image classification__

% * __AlexNet.__  Although convolutional neural networks (CNNs) have been around since the 
% 1970s, it was the ImageNet competition of 2012 and the superior results produced by the AlexNet 
% architecture [@Krizhevsky:2012] that spurred its subsequent popularity such that CNNs are now 
% the preferred approach to image-based neural networks.  Although originally only 2-D, both 
% 2-D and 3-D implementations have been implemented.  Example test code employs the MNIST
% data set for classifying handwritten digits directly downloadable within R.

% * __Vgg16/Vgg19.__ OxfordNet, or VGG, architectures [@Simonyan:2014] are much deeper than AlexNet and featured
% well in the 2014 ImageNet challenge.  We implemented popular 16- and 19-layer versions for 
% ANTsRNet.  Given the simplicity and excellent performance, these form the classification component
% of such object detection architectures as the multibox Single-Shot Detection (SSD) network 
% described below.  Both 2-D and 3-D versions have been implemented.   Example test code 
% employs the MNIST data set.

% * __GoogLeNet.__  GoogLeNet, or Inception (version v3) [@Szegedy:2015], is a 22-layer network 
% characterized by _inception blocks_ meant to reduce the number of parameters necessary to learn 
% the targeted function.  The architecture prevents a straightforward 3-D implementation so only
% a 2-D architecture is currently available.  Example test code employs the MNIST data set.

% * __ResNet/ResNeXt.__  The original ResNet architecture [@He:2015], along with a variant known 
% as _ResNeXt_[@Xie:2016], is also included in ANTsRNet.  ResNet, characterized by specialized blocks and
% skip connections, won the ImageNet challenge in 2015.  Both 2-D and 3-D versions have been 
% implemented.   Example test code employs the MNIST data set.

% *  __DenseNet.__  The DenseNet architecture [@Huang:2016] is based on the observation that performance is
% typically enhanced with shorter connections between the layers and the input.  This leads to
% an architecture in which every layer is connected to every other layer substantially reducing
% the number of parameters as well as other benefits.  Both 2-D and 3-D versions have been 
% implemented.

% __Object detection__

% * __SSD7/SSD300/SSD512.__ A common preprocssing step in many medical imaging tsks is the localization
% of an object or region of interest.  The Multibox Single-Shot Detection (SSD) algorithm is a 
% well-known architecture with good performance [@Liu:2015]. We have implemented the original 2-D '300'- and 
% '512'-style SSD networks in addition to their 3-D extensions.  As these networks require significant
% training for determining optimal weighting, we also implemented a smaller architecture known as SSD7
% which does not have such training data requirements.  We also extended this architecture to 3-D.
% A self-contained 2-D example of labeled faces 
% demonstrates training and testing of the SSD7 architecture.  

% __Image segmentation__

% * __U-Net/V-net.__  Extending fully convolutional neural networks (fCNN) by including an upsampling
% decoding path with skip connections linking corresponding encoding/decoding layers, the authors of
% U-net [@Ronneberger:2015] created a well-performing deep learning segmentation framework for 2-D images.
% This was later extended to 3-D with a custom Dice loss function in [@Milletari:2016] denoted as
% V-net.  Both 2-D and 3-D versions are implemented with a custom loss Dice function based on our 
% work in the Insight Toolkit [@tustison2009].  We have also created specialized decoding and encoding 
% utilities for translating between ANTs images and data representations necessary for Keras operations.
% Examples include a left/right lung segmentation example which includes a demonstration of our 
% unique template-based data augmentation strategy (see below).




